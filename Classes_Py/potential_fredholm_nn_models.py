# -*- coding: utf-8 -*-
"""potential_fredholm_nn_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gcxIRBs5FwAYUdYULhvM1nR8kLR9QbDP
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

#  FredholmNeuralNetwork and Potential Fredholm NN class definitions for the application to elliptic PDEs

# Class that is used for the Boundary Integral Equation via the Fredholm NN for the Poisson PDE

class FredholmNeuralNetwork_Poisson(nn.Module):
    def __init__(self, grid_dictionary, kernel, grid_step, K, input_size, output_size, km_constant, func_fn, precomputed_integral_map):
        super(FredholmNeuralNetwork_Poisson, self).__init__()

        self.grid_dictionary = grid_dictionary
        self.kernel = kernel
        self.grid_step = grid_step
        self.K = K
        self.km_constant = km_constant
        self.func_fn = func_fn
        self.precomputed_integral_map = precomputed_integral_map

        # Store dimensions for each layer
        self.layer_sizes = [input_size] + [len(grid_dictionary[f'layer_{i}']) for i in range(K + 1)]

    def additive(self, out_values):
        """Fetch precomputed additive values for x_list."""
        out_values = out_values.numpy() if isinstance(out_values, torch.Tensor) else out_values
        additive_values = []

        # Convert the precomputed integral map into a sorted array for fast lookup
        precomputed_grid = np.array(list(self.precomputed_integral_map.keys()))
        precomputed_values = np.array(list(self.precomputed_integral_map.values()))

        for value in out_values:
            # Find the closest grid point to the current value
            idx = np.abs(precomputed_grid - value).argmin()
            closest_value = precomputed_values[idx]

            # Compute the additive term
            additive_values.append(2 * (self.func_fn(value) - closest_value))

        return np.array(additive_values)

    def compute_weights_and_biases(self):
        """Precomputes weights and biases based on the grid using vectorized operations."""
        weights = []
        biases = []

        for i in range(self.K + 1):
            if i == 0:
                # Boundary condition for the first layer
                mat = np.identity(self.layer_sizes[i])
                weights.append(torch.tensor(mat, dtype=torch.float32))
                biases.append(torch.zeros(self.layer_sizes[i], dtype=torch.float32))
            else:
                # Vectorized kernel computation for weight matrix
                grid_prev = np.expand_dims(self.grid_dictionary[f'layer_{i - 1}'], axis=1)  # [N, 1]
                grid_curr = np.expand_dims(self.grid_dictionary[f'layer_{i}'], axis=0)    # [1, M]

                weight_matrix = (
                    self.kernel(grid_prev, grid_curr) * self.grid_step * self.km_constant +
                    (1 - self.km_constant) * ((grid_prev - grid_curr) == 0.0)
                )  # [N, M]
                weights.append(torch.tensor(weight_matrix, dtype=torch.float32))

                # Squeeze grid_curr from shape [1, M] to [M]
                grid_curr_squeezed = grid_curr.squeeze(0)  # shape [M]

                # Compute the additive term => shape (M,)
                bias_vector = self.additive(grid_curr_squeezed)*self.km_constant
                biases.append(torch.tensor(bias_vector, dtype=torch.float32))

        return weights, biases

    def forward(self, predict_array):
        # Precompute weights and biases
        weights, biases = self.compute_weights_and_biases()

        # Pass input through the dynamically updated network
        x = torch.ones(len(self.grid_dictionary['layer_0']), dtype=torch.float32)
        for i in range(self.K + 1):
            x = torch.matmul(weights[i].T, x) + biases[i]

        # Compute the last hidden layer output
        prediction = x

        return prediction.squeeze()

## Class for the Potential Fredholm NN to solve the Poisson PDE

class PotentialFredholmNeuralNetwork_Poisson(nn.Module):
    def __init__(self, fredholm_model, diff_potentials_fn, potential_boundary_fn, precomputed_integral_out, plot_BIF=False):
        super(PotentialFredholmNeuralNetwork_Poisson, self).__init__()
        self.fredholm_model = fredholm_model
        self.diff_potentials_fn = diff_potentials_fn
        self.potential_boundary_fn = potential_boundary_fn
        self.precomputed_integral_out = precomputed_integral_out
        self.plot_BIF = plot_BIF

    def forward(self, input, r_out, theta_out, phi_grid, grid_step):
        phi_grid = torch.tensor(phi_grid, dtype=torch.float32) if isinstance(phi_grid, np.ndarray) else phi_grid
        theta_out = torch.tensor(theta_out, dtype=torch.float32) if isinstance(theta_out, np.ndarray) else theta_out

        fnn_output = self.fredholm_model(input).to(dtype=torch.float32)

        if self.plot_BIF:
          plt.figure(figsize=(5, 4))
          plt.plot(input.numpy(), fnn_output.detach().numpy(), label="Model Output")
          plt.xlabel("Predict Array (x_list)")
          plt.ylabel("Output")
          plt.title("Boundary function")
          plt.legend()
          plt.grid(True)
          plt.show()

        # Additional hidden layer
        hidden_weights = torch.eye(len(phi_grid), dtype=torch.float32) # Construct Identity matrix for the weights in the additional hidden layer
        theta_indices = torch.argmin(torch.abs(phi_grid.unsqueeze(0) - theta_out.unsqueeze(-1)), dim=-1) # find corresponding Î²(x*) for substraction below
        fnn_output_theta = fnn_output[theta_indices]
        fnn_output_theta_expanded = fnn_output_theta.unsqueeze(0).repeat(len(r_out), 1).unsqueeze(-1)
        hidden_bias = -fnn_output_theta_expanded
        hidden_output = fnn_output.unsqueeze(0).unsqueeze(0) + hidden_bias

        # Output layer - r_out and theta_out are "tensored" via the potential and diff potential functions
        output_weights = torch.tensor(self.diff_potentials_fn(phi_grid, r_out, theta_out) * grid_step, dtype=torch.float32) # Multiply by the difference in potentials for the limit-approaching term
        potential_boundary_term = self.potential_boundary_fn(phi_grid, r_out, theta_out)

        bias_output = (
            torch.sum(fnn_output.unsqueeze(0).unsqueeze(0) * potential_boundary_term, dim=-1) * grid_step +
            0.5 * fnn_output_theta.unsqueeze(0).repeat(len(r_out), 1)) # Calculate the first part of the bias term as the integral of the potential kernel*boundary function

        poisson_integral = self.precomputed_integral_out
        poisson_integral = torch.tensor(poisson_integral, dtype = torch.float32)
        print(bias_output.shape)
        print(poisson_integral.shape)
        bias_output += poisson_integral  # Add precomputed integral of fundamental*source for each (r_o, theta_o)

        output_weights = output_weights.unsqueeze(-1)
        final_output = torch.matmul(hidden_output.unsqueeze(-2), output_weights).squeeze(-2)
        final_output += bias_output.unsqueeze(-1)
        return final_output

